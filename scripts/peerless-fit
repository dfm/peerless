#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import h5py
import emcee
import pickle
import shutil
import argparse
import numpy as np
from peerless.pool import MPIOptimizedPool as MPIPool


def lnprob(theta):
    if not compute_blob:
        return model.lnprob(theta, compute_blob=False)
    return model.lnprob(theta)


parser = argparse.ArgumentParser(description="model some light curves")

parser.add_argument("filename", help="the initialized pickle model")
parser.add_argument("--nwalkers", type=int, default=40,
                    help="the number of walkers")
parser.add_argument("--clobber", action="store_true",
                    help="clobber existing output")
parser.add_argument("--resample1", action="store_true",
                    help="resample stuck walkers")
parser.add_argument("--resample2", action="store_true",
                    help="resample near best walker")
parser.add_argument("--nburn", type=int, default=500,
                    help="the number of burn-in MCMC steps")
parser.add_argument("--burniter", type=int, default=2,
                    help="the number of burn-in iterations")
parser.add_argument("--nsteps", type=int, default=50000,
                    help="the number of production MCMC steps")
parser.add_argument("--block", type=int, default=10,
                    help="the number of MCMC steps per proposal type")
parser.add_argument("--thin", type=int, default=10,
                    help="the number of MCMC steps per save")

args = parser.parse_args()

with open(args.filename, "rb") as f:
    model = pickle.load(f)
model.system.central.dilution = 0.0
model.system.freeze_parameter("central:dilution")
compute_blob = True  # len(model.fit_lcs) <= 2


def mh_proposal(x):
    q = np.array(x)
    k, d = q.shape
    i = np.random.randint(d, size=k)
    q[(range(k), i)] += (
        np.exp(np.random.uniform(-10, 2, size=k)) * np.random.randn(k)
    )
    return q


def create_file(chain_fn, nwalkers):
    with h5py.File(chain_fn, "w") as f:
        for k, v in model.spec.items():
            f.attrs[k] = v
        f.create_dataset("chain", shape=(args.nsteps, nwalkers),
                         dtype=[(k, np.float64) for k in cols])
        f.create_dataset("lnprob", shape=(args.nsteps, nwalkers))
        f.create_dataset("lnprior", shape=(args.nsteps, nwalkers))
        f.create_dataset("params", shape=(args.nsteps, nwalkers),
                         dtype=[("ncadence", np.int64),
                                ("period", np.float64),
                                ("impact", np.float64),
                                ("eccen", np.float64),
                                ("depth", np.float64)])

        data = np.array([
            (i, l.time[j], l.flux[j], l.ferr[j])
            for i, l in enumerate(model.fit_lcs)
            for j in range(len(l.time))
        ], dtype=[("chunk", np.int64), ("time", np.float64),
                  ("flux", np.float64), ("ferr", np.float64)])
        f.create_dataset("data", data=data)


# Initialize the MPI-based pool used for parallelization.
with MPIPool() as pool:
    if not pool.is_master():
        # Wait for instructions from the master process.
        pool.wait()
        sys.exit(0)

    basedir = os.path.split(args.filename)[0]

    system = model.system
    cols = system.get_parameter_names()

    # Set up the output.
    chain_fn = os.path.join(basedir, "chain.h5")
    if args.clobber or not os.path.exists(chain_fn):
        p0 = system.get_vector()
        m = np.isfinite(p0)
        for _ in range(100):
            p0[np.isnan(p0)] = 0.0
            p0[(p0 < 0.0) & (~m)] = -10.0
            p0[(p0 > 0.0) & (~m)] = 10.0
            m = np.isfinite(p0)
            if np.all(m):
                break
        else:
            raise ValueError("invalid starting coordinates")

        ndim, nwalkers = len(p0), args.nwalkers
        while nwalkers <= ndim * 2:
            nwalkers += args.nwalkers
        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, pool=pool)

        create_file(chain_fn, nwalkers)

        # Run the MCMC.
        burniter = max(1, args.burniter)
        for i in range(burniter):
            print("Burn-in: {0}".format(i+1))
            coord = np.array(p0)
            p0 = p0[None, :] + 1e-6 * np.random.randn(nwalkers, ndim)

            # Don't allow -inf initialization.
            lp = np.array([lnprob(v)[0] for v in p0])
            m = ~np.isfinite(lp)
            for _ in range(100):
                p0[m] = coord[None, :] + 1e-6 * np.random.randn(m.sum(), ndim)
                lp[m] = np.array([lnprob(v)[0] for v in p0[m]])
                m = ~np.isfinite(lp)
                if np.all(np.isfinite(lp)):
                    break
            else:
                raise ValueError("invalid starting coordinates")

            ret = sampler.run_mcmc(p0, args.nburn)
            p0 = ret[0]
            if i < burniter - 1:
                p0 = sampler.flatchain[np.argmax(sampler.flatlnprobability)]

        i0 = 0

    elif args.resample1 and os.path.exists(chain_fn):
        print("resampling...")
        with h5py.File(chain_fn, "r") as f:
            b = f.attrs["step"]
            a = b // 3
            c = 10
            chain = f["chain"][a:b:c]

        # Resample from walkers with good ESJD.
        names = chain.dtype.names
        ndim = len(names)
        nwalkers = chain.shape[1]
        jump = np.diff(chain[names[0]], axis=0)
        esjd = np.mean(jump**2, axis=0)
        std = np.sqrt(np.mean((esjd - esjd.max()) ** 2))
        m = esjd < esjd.max() - std
        flatchain = chain[:, m].flatten()
        p0 = np.array([[flatchain[k][i] for k in names]
                       for i in np.random.randint(len(flatchain),
                                                  size=nwalkers)])

        # Don't allow -inf initialization.
        lp = np.array([lnprob(v)[0] for v in p0])
        m = ~np.isfinite(lp)
        while np.any(m):
            p0[m] = [[flatchain[k][i] for k in names]
                     for i in np.random.randint(len(flatchain), size=m.sum())]
            lp[m] = np.array([lnprob(v)[0] for v in p0[m]])
            m = ~np.isfinite(lp)

        # Move the old chain file.
        old_fn = chain_fn + ".bkp"
        shutil.move(chain_fn, old_fn)
        create_file(chain_fn, nwalkers)

        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, pool=pool)
        i0 = 0

    elif args.resample2 and os.path.exists(chain_fn):
        print("resampling (type 2)...")
        with h5py.File(chain_fn, "r") as f:
            b = f.attrs["step"]
            chain = f["chain"][:b]
            lnp = f["lnprob"][:b]

        # Resample around the best walker.
        names = chain.dtype.names
        ndim = len(names)
        nwalkers = chain.shape[1]
        n, w = np.unravel_index(np.argmax(lnp), lnp.shape)
        coord = np.array([chain[k][n, w] for k in names])
        p0 = coord[None, :] + 1e-8 * np.random.randn(nwalkers, ndim)

        # Don't allow -inf initialization.
        lp = np.array([lnprob(v)[0] for v in p0])
        m = ~np.isfinite(lp)
        while np.any(m):
            p0[m] = coord[None, :] + 1e-8 * np.random.randn(m.sum(), ndim)
            lp[m] = np.array([lnprob(v)[0] for v in p0[m]])
            m = ~np.isfinite(lp)

        # Move the old chain file.
        old_fn = chain_fn + ".bkp"
        shutil.move(chain_fn, old_fn)
        create_file(chain_fn, nwalkers)

        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, pool=pool)
        i0 = 0

    else:
        print("restarting...")
        with h5py.File(chain_fn, "a") as f:
            n = f.attrs["step"] - 1
            p0 = np.array([f["chain"][n][k] for k in cols]).T
            nwalkers, ndim = p0.shape
            ntot = n + 1 + args.nsteps

            # Resize.
            ds = ["chain", "lnprob", "lnprior", "params"]
            for k in ds:
                k2 = k + "_2"
                f[k2] = f[k]
                del f[k]
                s = list(f[k2].shape)
                s[0] = ntot
                f.create_dataset(k, shape=s, dtype=f[k2].dtype)
                f[k][:n+1] = f[k2][:n+1]
                del f[k2]

        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, pool=pool)
        i0 = n + 1

    print("Production")
    sampler.reset()
    pos = np.array(p0)
    i = i0
    while True:

        # Randomly select a proposal.
        if np.random.rand() < 0.8:
            s = sampler.sample(pos, iterations=args.thin*args.block,
                               storechain=False)
        else:
            s = sampler.sample(pos, iterations=args.thin*args.block,
                               storechain=False, mh_proposal=mh_proposal)

        # Sample using that proposal.
        for i2, ret in enumerate(s):
            pos, lnp, _, blob = ret
            if (i2 + 1) % args.thin != 0:
                continue
            with h5py.File(chain_fn, "a") as f:
                for n in range(nwalkers):
                    for j, k in enumerate(cols):
                        f["chain"][i, n, k] = pos[n, j]

                    f["params"][i, n, "ncadence"] = blob[n][1]
                    f["params"][i, n, "period"] = blob[n][0][0]
                    f["params"][i, n, "eccen"] = blob[n][0][1]
                    f["params"][i, n, "impact"] = blob[n][0][2]
                    f["params"][i, n, "depth"] = blob[n][2]

                    f["lnprior"][i, n] = blob[n][3]

                f["lnprob"][i] = lnp
                f.attrs["step"] = i + 1

            i += 1
            if i >= i0 + args.nsteps:
                break
