#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import h5py
import emcee
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as pl
from emcee.utils import MPIPool

from peerless.fit import setup_fit
from peerless.catalogs import KICatalog


def lnprob(theta):
    return model(theta)

parser = argparse.ArgumentParser(description="model some light curves")

parser.add_argument("candidates", help="the candidate database")
parser.add_argument("kicid", type=int, help="fit a specific KIC")
parser.add_argument("-o", "--output-dir", default="fits",
                    help="the output directory")
parser.add_argument("--no-remove-kois", action="store_true",
                    help="leave the known KOIs in the light curves")
parser.add_argument("--max-fit-data", type=int, default=250,
                    help="the maximum number of points per light curve")
parser.add_argument("--nburn", type=int, default=500,
                    help="the number of burn-in MCMC steps")
parser.add_argument("--burniter", type=int, default=2,
                    help="the number of burn-in iterations")
parser.add_argument("--nsteps", type=int, default=50000,
                    help="the number of production MCMC steps")

args = parser.parse_args()

kicid = args.kicid

# Load the candidate list.
cands = pd.read_csv(args.candidates)
cands = cands[cands.kicid == args.kicid]

# Load the stellar catalog.
kic = KICatalog().df
star = kic[kic.kepid == args.kicid]

# Initialize.
system = dict(
    kicid=kicid,
    srad=float(star.radius),
    srad_err=0.5 * float(star.radius_err1 - star.radius_err2),
    smass=float(star.mass),
    smass_err=0.5 * float(star.mass_err1 - star.mass_err2),
)

# Multiple transits.
if len(cands) > 1:
    times = np.sort(cands.transit_time)
    system["period"] = np.mean(np.diff(times))
    system["t0"] = times[0]
    row = cands.mean()
else:
    system["period"] = 2000.0
    system["t0"] = float(cands.transit_time)
    row = cands.iloc[0]

# Initial parameters.
system["radius"] = float(row.transit_ror * star.radius)
system["impact"] = 0.0

# Initialize the model.
model = setup_fit(system, remove_kois=not args.no_remove_kois,
                  max_points=args.max_fit_data)

# Initialize the MPI-based pool used for parallelization.
pool = MPIPool()

if not pool.is_master():
    # Wait for instructions from the master process.
    pool.wait()
    sys.exit(0)

basedir = os.path.join(args.output_dir, "{0}".format(kicid))
os.makedirs(basedir, exist_ok=True)
fig = model.plot()

fig.savefig(os.path.join(basedir, "init1.png"))
pl.close(fig)
model.optimize()
fig = model.plot()
fig.savefig(os.path.join(basedir, "init2.png"))
pl.close(fig)

cols = system.get_parameter_names()
p0 = system.get_vector()
ndim, nwalkers = len(p0), 36
sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, pool=pool)

# Set up the output.
chain_fn = os.path.join(basedir, "chain.h5")
with h5py.File(chain_fn, "w") as f:
    f.create_dataset("chain", shape=(args.nsteps, nwalkers),
                     dtype=[(k, np.float64) for k in cols])
    f.create_dataset("lnprob", shape=(args.nsteps, nwalkers))
    f.create_dataset("params", shape=(args.nsteps, nwalkers),
                     dtype=[("ncadence", np.int64),
                            ("period", np.float64),
                            ("impact", np.float64),
                            ("eccen", np.float64)])

    n = sum(len(lc.time) for lc in model.fit_lcs)
    f.create_dataset("pred", shape=(args.nsteps, nwalkers, 2, n))

    data = np.array([
        (i, l.time[j], l.flux[j], l.ferr[j])
        for i, l in enumerate(model.fit_lcs) for j in range(len(l.time))
    ], dtype=[("chunk", np.int64), ("time", np.float64),
              ("flux", np.float64), ("ferr", np.float64)])
    f.create_dataset("data", data=data)

# Run the MCMC.
burniter = max(1, args.burniter)
for i in range(burniter):
    print("Burn-in: {0}".format(i+1))
    p0 = p0[None, :] + 1e-4 * np.random.randn(nwalkers, ndim)
    p0, _, _, _ = sampler.run_mcmc(p0, args.nburn)
    if i < burniter - 1:
        p0 = sampler.flatchain[np.argmax(sampler.flatlnprobability)]

print("Production")
sampler.reset()
for i, (pos, lnp, _, blob) in enumerate(sampler.sample(p0,
                                                       iterations=args.nsteps,
                                                       storechain=False)):
    with h5py.File(chain_fn, "a") as f:
        for n in range(nwalkers):
            for j, k in enumerate(cols):
                f["chain"][i, n, k] = pos[n, j]

            f["params"][i, n, "ncadence"] = blob[n][1]
            f["params"][i, n, "period"] = blob[n][0][0]
            f["params"][i, n, "eccen"] = blob[n][0][1]
            f["params"][i, n, "impact"] = blob[n][0][2]

            f["pred"][i, n, 0] = np.concatenate([b[0] for b in blob[n][2]])
            f["pred"][i, n, 1] = np.concatenate([b[1] for b in blob[n][2]])

        f["lnprob"][i] = lnp
        f.attrs["step"] = i

# Close the processes.
pool.close()
