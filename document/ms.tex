% Copyright 2015-2016 Dan Foreman-Mackey and the co-authors listed below.

\documentclass[manuscript, letterpaper]{aastex6}

\pdfoutput=1

\usepackage{url}
\usepackage{amssymb,amsmath}
\usepackage{natbib}
\bibliographystyle{aasjournal}

% ----------------------------------- %
% start of AASTeX mods by DWH and DFM %
% ----------------------------------- %

\setlength{\voffset}{0in}
\setlength{\hoffset}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}
\setlength{\headheight}{0ex}
\setlength{\headsep}{\baselinestretch\baselineskip} % this is 2 lines in ``manuscript''
\setlength{\topmargin}{-\headsep}

\linespread{0.54} % close to 10/13 spacing in ``manuscript''
\setlength{\parindent}{0.54\baselineskip}
\hypersetup{colorlinks = false}
\makeatletter % you know you are living your life wrong when you need to do this
\long\def\frontmatter@title@above{
\vspace*{-\headsep}\vspace*{\headheight}
\noindent\footnotesize
{\noindent\footnotesize\textsc{\@journalinfo}}\par
{\noindent\scriptsize Preprint typeset using \LaTeX\ style AASTeX6 with
modifications by David W. Hogg and Daniel Foreman-Mackey.
}\par\vspace*{-\baselineskip}\vspace*{0.625in}
}%
\makeatother

% Section spacing:
\makeatletter
\let\origsection\section
\renewcommand\section{\@ifstar{\starsection}{\nostarsection}}
\newcommand\nostarsection[1]{\sectionprelude\origsection{#1}}
\newcommand\starsection[1]{\sectionprelude\origsection*{#1}}
\newcommand\sectionprelude{\vspace{1em}}
\makeatother

\sloppy\sloppypar

% ------------------ %
% end of AASTeX mods %
% ------------------ %

% Projects:
\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\kepler}{\project{Kepler}}
\newcommand{\KT}{\project{K2}}
\newcommand{\tess}{\project{TESS}}
\newcommand{\pdc}{\project{PDC}}
\newcommand{\bls}{\project{BLS}}

\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}
\newcommand{\True}{\foreign{True}}
\newcommand{\Truth}{\foreign{Truth}}

\newcommand{\dfmfigref}[1]{\ref{fig:#1}}
\newcommand{\dfmFig}[1]{Figure~\dfmfigref{#1}}
\newcommand{\dfmfig}[1]{\dfmFig{#1}}
\newcommand{\dfmfiglabel}[1]{\label{fig:#1}}

% \newcommand{\Tab}[1]{Table~\ref{tab:#1}}
% \newcommand{\tab}[1]{\Tab{#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}

\renewcommand{\eqref}[1]{\ref{eq:#1}}
\newcommand{\Eq}[1]{Equation~(\eqref{#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqalt}[1]{Equation~\eqref{#1}}
\newcommand{\eqlabel}[1]{\label{eq:#1}}

\newcommand{\sectionname}{Section}
\newcommand{\sectref}[1]{\ref{sect:#1}}
\newcommand{\Sect}[1]{\sectionname~\sectref{#1}}
\newcommand{\sect}[1]{\Sect{#1}}
\newcommand{\sectalt}[1]{\sectref{#1}}
\newcommand{\App}[1]{Appendix~\sectref{#1}}
\newcommand{\app}[1]{\App{#1}}
\newcommand{\sectlabel}[1]{\label{sect:#1}}

\newcommand{\T}{\ensuremath{\mathrm{T}}}
\newcommand{\dd}{\ensuremath{\,\mathrm{d}}}
\newcommand{\unit}[1]{{\ensuremath{\,\mathrm{#1}}}}
\newcommand{\bvec}[1]{{\ensuremath{\boldsymbol{#1}}}}
\newcommand{\appropto}{\mathrel{\vcenter{
  \offinterlineskip\halign{\hfil$##$\cr
    \propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}
\newcommand{\densityunit}{{\ensuremath{\mathrm{nat}^{-2}}}}


% TO DOS
\newcommand{\todo}[3]{{\color{#2}\emph{#1}: #3}}
\newcommand{\dfmtodo}[1]{\todo{DFM}{red}{#1}}
\newcommand{\hoggtodo}[1]{\todo{HOGG}{blue}{#1}}


% Helpers for this paper:
\newcommand{\license}{MIT License}
\newcommand{\paper}{paper}

% Notation for this paper:
\newcommand{\meanpars}{{\ensuremath{\bvec{\theta}}}}
\newcommand{\kernpars}{{\ensuremath{\bvec{\alpha}}}}
\newcommand{\params}{{\ensuremath{\bvec{w}}}}
\newcommand{\poppars}{{\ensuremath{\bvec{\beta}}}}
\newcommand{\rate}{{\ensuremath{\Gamma}}}


\shorttitle{The population of long-period exoplanets}
\shortauthors{Foreman-Mackey, Hogg, Morton, \etal}
% \submitted{Submitted to \textit{The Astrophysical Journal}}

\begin{document}

\title{%
The population of long-period exoplanets --- \\
Fully-automated discovery \& characterization of
long-period transiting exoplanet candidates in the \kepler\ archive
\vspace{-3\baselineskip}  % OMG AASTEX6 IS SO BROKEN
}

\newcounter{affilcounter}
\setcounter{affilcounter}{2}
\altaffiltext{1}{\url{danfm@uw.edu}; Sagan Fellow}

\edef \uw {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\uw}       {Astronomy Department, University of Washington,
                          Seattle, WA, 98195, USA}

\edef \scda {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\scda}     {Simons Center for Data Analysis, 160 Fifth Avenue,
                          7th floor, New York, NY 10010, USA}

\edef \nyu       {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\nyu}      {Center for Cosmology and Particle Physics,
                          New York University,
                          4 Washington Place, New York, NY, 10003, USA}

\edef \cds       {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\cds}      {Center for Data Science, New York University,
                          726 Broadway, 7th Floor, New York, NY, 10003, USA}

\edef \mpia      {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\mpia}     {Max-Planck-Institut f\"ur Astronomie,
                          K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\edef \princeton {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\princeton}{Department of Astrophysics, Princeton University,
                          Princeton, NJ, 08544, USA}

\edef \mpis      {\arabic{affilcounter}}\stepcounter{affilcounter}
\altaffiltext{\mpis}     {Max Planck Institute for Intelligent Systems
                          Spemannstrasse 38, 72076 T\"ubingen, Germany}

\author{%
    Daniel~Foreman-Mackey\altaffilmark{1,\uw},
    David~W.~Hogg\altaffilmark{\scda,\nyu,\mpia,\cds},
    Timothy~D.~Morton\altaffilmark{\princeton},
    Bernhard~Sch\"olkopf\altaffilmark{\mpis},
    Eric~Agol\altaffilmark{\uw},
    and others
}



\begin{abstract}

The \kepler\ Mission has discovered thousands of exoplanets and revolutionized
our understanding of their population.
This large, homogeneous catalog of discoveries has enabled rigorous studies of
the occurrence rate of exoplanets and extra-Solar planetary systems as a
function of their physical properties.
Transit survey like \kepler\ are most sensitive to planets with shorter
orbital periods than the gas giant planets that dominate the dynamics of our
Solar System.
We performed a fully-automated search for the transits of long-period
exoplanets in the archival \kepler\ light curves and announce XXX planet
candidates.
Since our method involves no human intervention, we empirically characterize
the completeness and reliability of our search.
Based on these results, we measure the average occurrence rate of exoplanets
smaller than Jupiter and with orbital periods longer than 700 days to be $\dd
N = YYY \pm ZZZ\dd \ln P \dd \ln R$.

\end{abstract}

\keywords{%
methods: data analysis
---
methods: statistical
---
catalogs
---
planetary systems
---
stars: statistics
}

\section{Introduction}

Data from the \kepler\ Mission has been used to discover thousands of
transiting exoplanets.
The systematic nature of these discoveries and careful quantification of
survey selection effects, search completeness, and catalog reliability has
enabled many diverse studies of the detailed frequency and distribution of
exoplanets \citep[for example,][]{Howard:2012, Petigura:2013,
Foreman-Mackey:2014, Dressing:2015, Burke:2015, Mulders:2015}.
So far, these results have been limited to relatively short orbital periods
because existing transit search methods require the observation of multiple
transits within the baseline of the data.
For \kepler, with a baseline of about four years, this sets an absolute upper
limit on the detectable periods of about two years.
In the Solar System, Jupiter~--~with a period of 12 years~--~dominates the
planetary dynamics and, since it would only exhibit at most one transit in the
\kepler\ data, an exo-Jupiter would be missed by most existing transit search
procedures.
It is possible to discover long-period planets like this using targeted radial
velocity (RV) surveys \citep[for example][]{Butler:2006, Knutson:2014,
Bryan:2016} but the cost of implementing a systematic RV search is
substantially higher than searching the existing and forthcoming photometric
data for single transits.

There are two main technical barriers to a systematic search for single
transit events.
The first is that the transit probability for long-period planets is very low;
scaling as $\propto P^{-5/3}$ for orbital periods longer than the
baseline of contiguous observations.
Therefore, even if long-period planets are intrinsically common, they will
be underrepresented in a transiting sample.
The second challenge is that there are many signals in the observed light
curves caused by stochastic processes~--~both instrumental and
astrophysical~--~that can masquerade as transits.
Even when the most sophisticated methods for removing this variability are
used, false signals far outnumber the true single transits in any traditional
search.

At the heart of all periodic transit search procedures is a filtering step
based on ``box least squares'' \citep[\bls;][]{Kovacs:2002}.
This step produces a list of candidate transit times that is then vetted to
remove the substantial fraction of false signals using some combination of
automated heuristics and expert curation.
In practice, the fraction of false signals can be substantially reduced by
requiring that at least three self-consistent transits be observed
\citep{Petigura:2013, Burke:2014, Rowe:2015, Coughlin:2015}.

Recent work has yielded discoveries of long-period transiting planets with
only one or two transits identified in archival \kepler\ and \KT\ light curves
by visual inspection \citep{Wang:2013, Kipping:2014a, Osborn:2016,
Kipping:2016, Uehara:2016, Wang:2015}.
Since all of these discoveries rely on human interaction, it is intractable to
reliably constrain the completeness of these catalogs and they cannot be used
to measure the occurrence rate of long-period planets.

In this \paper, we develop a systematic method of reliably discovering the
transits of large long-period companions in photometric time series
\emph{without human intervention}.
Since the search methodology is fully-automated, we can robustly measure the
search completeness~--~using injection and recovery tests~--~and use these
products to place probabilistic constraints on the occurrence rate of
long-period planets.
We apply this method to a subset of the archival data from the \kepler\
Mission and produce a catalog of discoveries.


\section{A fully-automated search method}

To find long-period exoplanets in the \kepler\ light curves, we search for
individual, high signal-to-noise transit signals using a fully-automated
procedure that can be broken into three main steps:
\begin{enumerate}
{\item an initial candidate search using a box-shaped matched filter,}
{\item light curve-level vetting (using automated model comparison) to remove
signals that don't match a transit shape, and}
{\item pixel-level vetting to remove some astrophysical false positives.}
\end{enumerate}
The following sections describe each of these steps in more detail.

The model comparison step (step 2) is the key component of our method that
enables robust automation but it is also computationally expensive because we
must estimate the marginalized likelihoods for the light curve under several
different models describing a transit and many other processes that ``look''
like transits but are actually caused by noise.
This step is also conservative; unless a signal is a very convincing transit,
it won't pass the test.
In practice, this means that all but the highest signal-to-noise events will
be rejected at this step.
Therefore, in the inexpensive first step~--~the initial candidate search~--~we
can restrict the candidate list to high signal-to-noise events without a
substantial loss in detection efficiency.

\subsection{Initial candidate events}

It is not computationally feasible to run a full model comparison at every
time in the light curve so we must first find potentially interesting events.
For our purposes, ``interesting'' means high signal-to-noise and previously
unknown.

To generate this list, we apply a standard ``box least squares'' (BLS;
\dfmtodo{CITE}) method with a single (non-periodic) box.
First, we filter the PDC (\dfmtodo{CITE}) light curves using a running
windowed median with a half-width of \dfmtodo{how many} to remove stellar
variability.
We then compute the signal-to-noise of the depth of a 0.6~day long transit on
a grid of times spanning the full \kepler\ baseline.
We only need to use a single transit duration because the following steps in
this procedure are only sensitive to transits with very high signal-to-noise
so, in practice, the results of this step are insensitive to the specific
choice of duration.

As previously mentioned, the following steps will only detect high
signal-to-noise transits.
To avoid edge effects, we apodize this detection scalar near any large gaps in
the time series using a logistic function with width equal to one transit
duration.
Finally, we estimate the noise in the time series using a robust running
windowed variance estimate of the detection scalar and accepting peaks more
than 25-times this noise as candidates.

\subsection{Light curve-level vetting}

In this step of the method, the goal is to discard any signals that are not
sufficiently ``transit-like'' in shape.
To quantify this decision, we perform a model comparison between a physical
transit model and a set of other parameterized models for systematics.
In order for a candidate to pass this vetting step, the transit model must be
``preferred'' to any other model as measured using the Bayesian Information
Criterion (BIC).
The BIC is not the optimal choice for this model comparison but it is
computationally intractable to compute thousands of precise marginalized
likelihoods for each model.
The BIC can be efficiently computed and it exhibits the desired
behavior~--~increasing with the likelihood but flexible models are
penalized~--~and we find that it performs sufficiently well in practice.

For up to three candidate transit times per light curve, we select a
contiguous chunk of PDC light curve approximately centered on the proposed
transit with no more than 500 cadences \dfmtodo{check me} and compute the BIC
of each model for this data set.
We will define the BIC for a model $k$ in the set of $K$ models is given by
\begin{eqnarray}
\mathrm{BIC}_k &=& \ln \mathcal{L}^* - \frac{J}{2}\,\log N
\end{eqnarray}
where the likelihood function $\mathcal{L}$ is evaluated at its maximum, $J$
is the number of free parameters in the model, and $N$ is the number of
data points in the data set.

For each model, we describe the data using a Gaussian Process (GP;
\dfmtodo{cite}) with a Mat\'ern-3/2 covariance and mean given by the chosen
model $m_k(t;\,\meanpars)$ parameterized by the parameter vector \meanpars.

The models are:
\begin{itemize}
{\item a limb-darkened, exposure time integrated transit light curve,}
{\item a pure Gaussian Process model to capture stellar variability,}
{\item a single outlier,}
{\item an step function, and}
{\item a box.}
\end{itemize}


\subsection{Pixel-level vetting}


\begin{figure*}[p]~\\
\begin{center}
\includegraphics[width=\textwidth]{figures/model_comp.pdf}
\end{center}
\caption{%
Representative examples of candidate events flagged by the initial search.
Each example falls into a different model category and the figure shows the
data as black points and the best fit mean model prediction.
The examples represent the following model categories:
\emph{(a)} variability, \emph{(b)} step, \emph{(c)} box, and \emph{(d)}
transit.
\dfmfiglabel{model-comp}}
\end{figure*}

\dfmfig{model-comp}


\section{A catalog of exoplanet \& binary candidates}


\subsection{Target selection}\sectlabel{data}

For the purposes of this \paper, we select the $\sim40,000$ brightest and
quietest G and K dwarfs from the \kepler\ catalog using the following
parameters:
\begin{itemize}
{\item $4200\unit{K} \le T_\mathrm{eff} \le 6100\unit{K}$,}
{\item $R_\star \le 1.15\,R_\odot$,}
{\item $K_p \le 15\unit{mag}$, and}
{\item $\mathrm{CDPP}_{7.5\unit{hrs}} \le 1000\unit{ppm}$.}
\end{itemize}
We also restrict the sample to only include targets with a data span of more
than two years and a duty cycle of better than $0.6$.
Since the \kepler\ data have been searched for shorter period planets
\dfmtodo{CITE Coughlin} and eclipsing binaries \dfmtodo{CITE EB catalog} than
targeted by this project, we censor these previously known targets.
For the known EBs, we simply remove these targets from the candidate list.
For the confirmed and candidate KOIs from \dfmtodo{Coughlin}, we remove data
within 2 transit durations of the known candidates.

\begin{figure}~\\
\begin{center}
\includegraphics{figures/targets.pdf}
\end{center}
\caption{%
Blah.
\dfmfiglabel{targets}}~\\
\end{figure}


We start with the PDC-MAP light curves downloaded from
MAST\footnote{\url{https://archive.stsci.edu/kepler/}}.



The \kepler\ Mission measured photometric time series for about 190,000 stars
at half-hour cadence for a baseline of over four years.
We aim to search these light curves for single transits of long-period planets
and single eclipses of binary stars.
These data are made available on
MAST\footnote{\url{https://archive.stsci.edu/kepler/}} and, for each target,
we downloaded the full set of long cadence light curve files provided by Data
Release 24 \citep{Thompson:2015}.
From these files, we extracted the PDC time series and split them into
``sections'' with no more than ten contiguous missing or flagged data points.
The PDC light curves have been corrected for the instrumental effects caused
by the spacecraft using a data-driven model of the focal plane
\citep{Stumpe:2012, Smith:2012}.
Crucially, an attempt is also made by the PDC procedure to remove sharp
instrumental artifacts like ``sudden pixel sensitivity dropouts (SPSDs)''.
The success rate of this correction procedure is much higher than in earlier
data releases but, as discussed in \sect{demo}, there remain some cases that
are not properly accounted for.

The goal of this project is to discover the transits of long-period planets
that have not yet been discovered.
Therefore, when studying the light curve of an eclipsing binary star or a star
with known transiting planet candidates~--~on shorter periods~--~we also remove
all the in-transit data for the candidate using the parameters provided by the
\project{NASA Exoplanet
Archive}\footnote{\url{http://exoplanetarchive.ipac.caltech.edu/}; We
downloaded the \texttt{cumulative} table of \kepler\ Objects of Interest on
2015-03-25.}.


\subsection{Parameter estimation}


\begin{figure*}~\\
\begin{center}
\includegraphics{figures/full_sample.pdf}
\end{center}
\caption{%
Blah.
\dfmfiglabel{full-sample}}~\\
\end{figure*}



\section{Empirical search completeness}

To measure the completeness of our long-period transit search method, we
exploit the fact that transit signals are sparse and rare.
Therefore, most light curves contain no transits and we can reliably measure
the recovery rate of our method on synthetic transit signals~--~with known
properties~--~injected into real light curves.
This procedure is standard practice in the transit literature and it has been
used to determine the completeness of the KOI catalog (\dfmtodo{cite}) and
other independent transit searches (\dfmtodo{cite}).

To reliably capture the full structure of the search completeness function,
the simulations must sample the (high-dimensional) space of all properties
that affect the probability of detecting a transit: the stellar properties
(including variability amplitudes and time scales), the planet's physical
properties and orbital elements, and any observational effects (noise,
spacecraft pointing variations, \etc).
For the modest goals of this paper, we only need a robust constraint on the
transit detection efficiency \emph{integrated} across the target sample but,
even so, many simulations per star are required.

The procedure for measuring the recovery rate of simulated transits is as
follows:
\begin{enumerate}
{\item First, a star is randomly selected from the target list, and the PDC
light curve and stellar properties for that star are loaded.}
{\item Planetary properties are sampled from the distributions listed in
\dfmtodo{some table} with phase uniformly distributed across the baseline of
observations. These properties are resampled until the transit is visible in
at least one non-flagged cadence.}
{\item The transit signal induced by this planet is computed and multiplied
into the PDC light curve.}
{\item The transit search method described in section \dfmtodo{some section}
(including de-trending and all automated vetting) is applied to this light
curve with the injected transit signal.}
{\item This candidate is flagged as recovered if at least one transit (within
\dfmtodo{some tolerance}) passes all the cuts imposed by the automated
vetting.}
\end{enumerate}

The fraction of recovered simulations as a function of the relevant parameters
gives an estimate of the search completeness or the probability of detecting
an exoplanet transit with a given set of parameters, \emph{conditioned on the
fact that it transits}.
We will call this function $Q_{\mathrm{det},k}(\params)$ where \params\ is the
set of all parameters affecting the transit detectability and $k$ is an index
running over target stars.

This detection efficiency must then be combined with the geometric transit
probability function and the window function.
For the star $k$, the geometric transit probability is given by \dfmtodo{cite}
\begin{eqnarray}
Q_{\mathrm{geom},k} (\params) &=& \frac{R_{\star,k}}{a_k}
    \, \frac{1 + e\,\sin\omega}{1-e^2} \\
&=& \left[\frac{4\,\pi^2}{G\,M_{\star,k}}\right]^{1/3}\,R_{\star,k}
    \, \left[\frac{1 + e\,\sin \omega}{1-e^2}\right]
    \, P^{-2/3}
\end{eqnarray}
where the parameters $e$, $\omega$, and $P$ are included in \params.
Approximating the window function using the binomial probability of observing
at least one transit \dfmtodo{cite bm14} we find
\begin{eqnarray}
Q_{\mathrm{win},k} (\params) &=& 1 - (1 - f_{\mathrm{duty},k})^{T_k/P}
\end{eqnarray}
where $f_{\mathrm{duty},k}$ is the duty cycle and $T_k$ is the full
observation baseline for target $k$.

Combining these detection effects, the total detection efficiency is given by
\begin{eqnarray}
Q_k(\params) &=& Q_{\mathrm{det},k}(\params) \,
                 Q_{\mathrm{win},k} (\params) \,
                 Q_{\mathrm{geom},k} (\params) \quad.
\end{eqnarray}
For the purposes of this \paper, we are not considering the occurrence rate of
exoplanets as a function of stellar properties; we will only measure an
average rate across the target sample that we previously selected.
Therefore, it is sufficient to estimate the marginalized detection efficiency
integrated with respect to our prior distributions on the nuisance parameters.
In this case, the only parameters that we will consider are planet radius and
orbital period.
Under this model, the relevant detection efficiency function for long-period
transiting planets is
\begin{eqnarray}\eqlabel{full-comp}
Q(R,\,P) &=& \frac{1}{K} \sum_{k=1}^{K} \int Q_k(\params) \,
    p(\params_{\{R,\,P\}}) \dd\params_{\{R,\,P\}}
\end{eqnarray}
where $\params_{\{R,\,P\}}$ indicates the set of all parameters except radius
and period.

Since the simulated parameters in the injection and recovery tests described
above were sampled from the prior distribution $p(\params_{\{R,\,P\}})$, the
easiest way to estimate \eq{full-comp} is to take the ratio of the weighted
histogram of the recovered injections to the weighted histogram of all
simulations where each simulation is weighted by
$Q_{\mathrm{win},k} (\params) \, Q_{\mathrm{geom},k} (\params)$ evaluated at
the parameters of the simulation.
\dfmtodo{Some figure} shows the measured completeness (\eq{full-comp}) as a
function of planet radius and orbital period.

\dfmtodo{Analytic fit?}

\begin{figure*}[p]~\\
\begin{center}
\includegraphics[width=\textwidth]{figures/completeness.pdf}
\end{center}
\caption{%
\dfmfiglabel{completeness}}
\end{figure*}


\section{The occurrence rate of long-period exoplanets}

Using the catalog of exoplanet discoveries (\dfmtodo{some section}) and the
measurement of the search completeness (\dfmtodo{some section}), we can now
estimate the occurrence rate of long-period exoplanets.
This inference can be simplified by making a few strong assumptions that are
only weakly justified.
First, we make the strong assumption that none of the candidates are
astrophysical false positives (background eclipsing binaries, the secondary
eclipse of a long-period binary system, \etc).
We revisit this assumption and discuss its validity in \dfmtodo{some section}.
Next, we model the occurrence of exoplanets as a Poisson process
(\dfmtodo{CITE}) with a rate function $\rate_{\poppars} (R,\,P)$ parameterized
by some parameters \poppars.
This assumption leads to the commonly used likelihood function
(\dfmtodo{CITE})
\begin{eqnarray}
\ln p (\{w_j\}_{j=1}^J\,|\,\poppars) =
    \sum_{j=1}^J \ln \rate_{\poppars} (R_j,\,P_j)
    - \int \rate_{\poppars} (R,\,P)\,Q(R,\,P)\dd R\dd P
    + \mathrm{constant} \quad.
\end{eqnarray}
Since our catalog of discoveries is small, we will only make limited
inferences about the population.
For the purposes of this paper, we will simply estimate the period of
long-period planets ($2\,\mathrm{yr} \le P < 15\,\mathrm{yr}$) in two radius
bins $0.1\,R_\mathrm{J} \le R < 0.5\,R_\mathrm{J}$ and $0.5\,R_\mathrm{J} \le
R < R_\mathrm{J}$.





\section{Astrophysical false positives}

Tim to write some words here.



\section{Discussion}\sectlabel{discussion}

We have developed a fully-automated method to search for the transits and
eclipses of long-period companions in photometric time series.
Applying this method to a subset of the \kepler\ archival light curves, we
discovered XX astrophysical transits.
Of these discoveries, at least about YY are likely to be planetary in nature.
Combining this catalog of discoveries with a measurement of the completeness
of our search method, we place a constraint on the occurrence rate of
long-period exoplanets.

Our method for transit detection finds convincing transit-shaped signals does
a model comparison between a physical transit model.



\acknowledgments
It is a pleasure to thank
\ldots
for helpful contributions to the ideas and code presented here.

DWH was partially supported by the National Science Foundation (grant
IIS-1124794), the National Aeronautics and Space Administration (grant
NNX12AI50G), and the Moore--Sloan Data Science Environment at NYU.

This research made use of the NASA \project{Astrophysics Data System} and the
NASA Exoplanet Archive.
The Exoplanet Archive is operated by the California Institute of Technology,
under contract with NASA under the Exoplanet Exploration Program.
This \paper\ includes data collected by the \kepler\ mission. Funding for the
\kepler\ mission is provided by the NASA Science Mission directorate.
We are grateful to the entire \kepler\ team, past and present.
Their tireless efforts were all essential to the tremendous success of the
mission and the successes of \KT, present and future.

These data were obtained from the Mikulski Archive for Space Telescopes
(MAST).
STScI is operated by the Association of Universities for Research in
Astronomy, Inc., under NASA contract NAS5-26555.
Support for MAST is provided by the NASA Office of Space Science via grant
NNX13AC07G and by other grants and contracts.

Computing resources were provided by High Performance Computing at New York
University.

\facility{Kepler}
\software{%
    \project{ceres} \citep{Agarwal:2016},
    \project{corner.py} \citep{Foreman-Mackey:2016},
    \project{emcee} \citep{Foreman-Mackey:2013},
    \project{george} \citep{Ambikasaran:2016},
	\project{matplotlib} \citep{Hunter:2007},
	\project{numpy} \citep{Van-Der-Walt:2011},
	\project{scipy} \citep{Jones:2001}}.

\newpage
\appendix

\section{Gaussian process regression}

Gaussian Processes (GPs) are a class of non-parametric, stochastic models that
have been demonstrated to be good effective models for the variability in
\kepler\ light curves.
A simple GP model can be used to capture residual non-transit variability in
light curves.
In this \paper, we use a GP model for two steps: light curve--level transit
shape vetting and parameter estimation.
A full discussion of GPs is beyond the scope of this \paper, so we will only
summarize the most relevant points here and direct an interested reader to
\dfmtodo{cite RW} for more details.

A GP model is specified by the following likelihood function
\begin{eqnarray}\eqlabel{gplike}
\mathcal{L} = \ln p(\bvec{y}\,|\,\meanpars,\,\kernpars) &=&
- \frac{1}{2}\,\bvec{r}(\meanpars)^\T\,K(\kernpars)^{-1}\,
    \bvec{r}(\meanpars)
- \frac{1}{2}\log\det K(\kernpars) - \frac{N}{2} \log{2\,\pi}
\end{eqnarray}
where \bvec{y} is a list of measurements in a scalar time series~--~in this
case, fluxes~--~measured at the times \bvec{t}, and
\begin{eqnarray}
\bvec{r}(\meanpars) &=& \bvec{y} - m(\bvec{t};\,\meanpars)
\end{eqnarray}
is the vector of residuals away from the mean model $m(\bvec{t};\,\meanpars)$.
For the purposes of this paper, we model the covariance matrix $K(\kernpars)$
using the Mat\'ern-3/2 kernel.
Under this model, the elements of $K(\kernpars)$ are given by
\begin{eqnarray}\eqlabel{matern}
\left[ K(\kernpars) \right]_{ij} &=& \sigma_i^2\,\delta_{ij}
    + \alpha^2 \left[ 1+\frac{|t_i - t_j|}{\sqrt{3}\,\tau} \right]
      \exp \left(-\frac{|t_i - t_j|}{\sqrt{3}\,\tau}\right)
\end{eqnarray}
where $\sigma_i$ is the reported uncertainty on the $i$-th measurement in the
time series and $\delta_{ij}$ is the Kronecker delta.

This covariance function (\eqalt{matern}) is specified by an amplitude
$\alpha$ and a time scale $\tau$ and we will simultaneously fit for these
hyperparameters $\kernpars=(\alpha,\,\tau)$ and the parameters of the mean
model \meanpars.
To efficiently find the parameter set that maximizes \eq{gplike} using a
non-linear optimization routine\footnote{We use the L-BFGS-B method as
implemented in SciPy \url{%
http://docs.scipy.org/doc/scipy/reference/generated/%
scipy.optimize.minimize.html}.},
it is useful to be able to compute the gradient of \eq{gplike} with respect to
the parameters \meanpars\ and \kernpars.
These gradients are given by
\begin{eqnarray}\eqlabel{gpmeangrad}
\frac{\dd\ln p(\bvec{y}\,|\,\meanpars,\,\kernpars)}{\dd \meanpars} &=&
\frac{\dd m(\bvec{t};\,\meanpars)}{\dd\meanpars}^\T \, K(\kernpars)^{-1} \,
    m(\bvec{t};\,\meanpars)
\end{eqnarray}
and
\begin{eqnarray}
\frac{\dd\ln p(\bvec{y}\,|\,\meanpars,\,\kernpars)}{\dd \kernpars} &=&
\frac{1}{2}\,\mathrm{Tr}\left(
    \left[ \bvec{\phi}\,\bvec{\phi}^\T - K(\kernpars)^{-1} \right]
    \,\frac{\dd K(\kernpars)}{\dd\kernpars}
\right)
\end{eqnarray}
where
\begin{eqnarray}
\bvec{\phi} &=& K(\kernpars)^{-1}\,\bvec{r}(\meanpars) \quad.
\end{eqnarray}

To evaluate \eq{gpmeangrad}, we must also evaluate the derivative of the mean
model with respect to its parameters.
For this \paper, the model $m(\bvec{t};\,\meanpars)$ will sometimes be the
limb-darkened, exposure time-integrated transit of a planet on a Keplerian
orbit and the parameters \meanpars\ are the physical and orbital parameters of
the planet and star.
Analytically computing the gradient of a simple transit model is possible
\citep{Pal:2008} but it becomes substantially more tedious as the model
becomes more realistic.
Therefore, we use a compile-time automatic differentiation library\footnote{%
More specifically, we use the \texttt{Jet} object from the BSD-licensed Ceres
Solver \url{http://ceres-solver.org}} \citep{Agarwal:2016} to compute first
derivatives of the full transit model to machine precision.


\clearpage
\bibliography{peerless}

\end{document}
